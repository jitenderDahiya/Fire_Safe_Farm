{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "headed-dependence",
   "metadata": {},
   "source": [
    "# Bush Fire Data:\n",
    "\n",
    "### Data Source: \n",
    "Fire History Records of Fires primarily on Public Land showing the fire scars\n",
    "https://discover.data.vic.gov.au/dataset/designated-bushfire-prone-area-bpa(08/09/2011 to 31/12/2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-model",
   "metadata": {},
   "source": [
    "### Have two files \n",
    "* postcode file\n",
    "* shape file \n",
    "    * Name of place\n",
    "    * coordinates of that place ( boundary coordinates) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-fight",
   "metadata": {},
   "source": [
    "### First need to get the codes for the only victoria \n",
    " that might would be easier to search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-struggle",
   "metadata": {},
   "source": [
    "## Postcode file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "### postcode file:\n",
    "\n",
    "pc = pd.read_csv(\"postcode.csv\")\n",
    "pc.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-neutral",
   "metadata": {},
   "source": [
    "* removing the unwanted columns and rows  as we want the data for all states of the victoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "newpc = pc.loc[(pc['admin code1'] == 'VIC')&(pc['postal code'] < 8000), \n",
    "               ['postal code','place name','admin name1', 'latitude', 'longitude']].reset_index(drop='True')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets save the file \n",
    "\n",
    "newpc.to_csv(\"postcode_vic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the postcode file\n",
    "\n",
    "pc_vic = pd.read_csv(\"postcode_vic.csv\")\n",
    "pc_vic.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-north",
   "metadata": {},
   "source": [
    "## Bushfire Shape file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-aquatic",
   "metadata": {},
   "source": [
    "#### shape file  extraction  is in two files:\n",
    "\n",
    "* location name and other data\n",
    "\n",
    "\n",
    "* coordinations of area burnt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyshp\n",
    "import shapefile\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = shapefile.Reader(r'C:\\Users\\JxD\\Desktop\\IE\\SDM841179\\ll_gda94\\sde_shape\\whole\\VIC\\FIRE\\layer\\fire_history.shp', encoding ='latin')\n",
    "\n",
    "# data.fields\n",
    "\n",
    "corrd = [i.points for i in data.shapes()]\n",
    "\n",
    "\n",
    "index=[]\n",
    "lat=[]\n",
    "long=[]\n",
    "\n",
    "for i,j in enumerate(corrd):\n",
    "    idx = i\n",
    "    for a,b in j:\n",
    "        index.append(i)\n",
    "        lat.append(a)\n",
    "        long.append(b)\n",
    "        \n",
    "DF = pd.DataFrame({'index':index, 'lat':lat,'long':long})\n",
    "DF.to_csv(\"corrdinates.csv\")\n",
    "\n",
    "\n",
    "\n",
    "col = data.fields[1:]\n",
    "col = [ i[0] for i in col]\n",
    "\n",
    "d_list = [i for i in data.records() ]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(d_list,columns=col )\n",
    "\n",
    "data.to_csv(\"data_from_shp.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-serum",
   "metadata": {},
   "source": [
    "### shape file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "### shape file \n",
    "shape = pd.read_csv('data_from_shp.csv')\n",
    "shape.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-volume",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape.groupby(['SEASON','FIRE_SVRTY']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape['FIRE_SVRTY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape['index']=shape.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### take the imp columns and make a new csv file\n",
    "### as data is big so will take the bushfire data from year 2008 to 2020\n",
    "\n",
    "\n",
    "df = shape.loc[shape['SEASON'] >= 2008,['index','SEASON',\"NAME\",\"AREA_HA\"]]\n",
    "\n",
    "df.to_csv(\"shape_2k8_20.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2k8_20 = pd.read_csv(\"shape_2k8_20.csv\")\n",
    "print(shape_2k8_20.shape)\n",
    "shape_2k8_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-accuracy",
   "metadata": {},
   "source": [
    "<strong> Can see that Name is not proper format according to the requirement <strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking missing values \n",
    "\n",
    "len(shape_2k8_20.loc[shape_2k8_20['NAME'].isna()])  ### where name value is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shape_2k8_20.loc[shape_2k8_20['NAME'].notna()]) ### where the name given, have to reformat it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-projection",
   "metadata": {},
   "source": [
    "<p> <b> So where the name is given we will reformat it and find the postcode with the help of postcode file and make new columns of these values.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making column for postcode and  place name\n",
    "shape_2k8_20['Place'] = ''\n",
    "shape_2k8_20['postcode'] = 0\n",
    "print(shape_2k8_20.columns)\n",
    "shape_2k8_20.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-syndicate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## if name not find in data then will add the \"NA\". \n",
    "\n",
    "for each in shape_2k8_20.loc[shape_2k8_20['NAME'].notna()].index:\n",
    "    if (each % 10000) == 0:\n",
    "        print(each)\n",
    "    place = str(shape_2k8_20.iloc[each,list(shape_2k8_20.columns).index('NAME')]).split(\"-\")[0].strip()\n",
    "    \n",
    "    shape_2k8_20.iloc[each, list(shape_2k8_20.columns).index('Place')] = place\n",
    "    \n",
    "    if len(pc_vic[pc_vic['place name'] == place]) !=0:\n",
    "        shape_2k8_20.iloc[each, list(shape_2k8_20.columns).index('postcode')] = pc_vic.iloc[pc_vic.loc[pc_vic['place name'] == str(place) ].index[0]][0]\n",
    "\n",
    "    else:\n",
    "        shape_2k8_20.iloc[each, list(shape_2k8_20.columns).index('postcode')] = \"NA\"\n",
    "        shape_2k8_20.iloc[each, list(shape_2k8_20.columns).index('Place')] = \"NA\"\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2k8_20.to_csv(\"shape2k8NA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-upper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape_2k8_20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-shadow",
   "metadata": {},
   "source": [
    "### Now the missing Name and 'NA'  are still present in data. Will sort that out later. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-picnic",
   "metadata": {},
   "source": [
    "### coordinates file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract the coordinates file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read the saved coordinates file\n",
    "\n",
    "corr = pd.read_csv('corrdinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### index of places with 'NA'   +  no name in shape file \n",
    "\n",
    "na = list(shape_2k8_20[shape_2k8_20['Place'] == 'NA']['index'])\n",
    "\n",
    "nName_na = list(shape_2k8_20.loc[shape_2k8_20['NAME'].isna()]['index']) + na\n",
    "\n",
    "len(nName_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### find all of the indexes at which we don't have nameand 'NA' with NO coordinates. \n",
    "\n",
    "mis_cor = []\n",
    "for i in nName_na:\n",
    "    if len(corr[corr['index'] == i]) ==0:\n",
    "        mis_cor.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mis_cor, columns=['mis_cor']).to_csv(\"mis_corr.csv\", index=False)  ## save the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_cor = pd.read_csv('mis_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_cor.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NO name \n",
    "\n",
    "mc = mis_cor['mis_cor'].values\n",
    "\n",
    "shape_2k8_20[shape_2k8_20['index'] == mc[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No coordinates\n",
    "corr[corr['index'] == mc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mc)  ### these are the number of data which dont have the name as well as the coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remain data which have corrdinates but no have name. will compute the name\n",
    "len(nName_na) - len(mc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "### index at which name is not present but coordinates are given. \n",
    "\n",
    "x = []\n",
    "for e in nName_na:\n",
    "    if (e not in mc):\n",
    "        x.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "## x contains all of the rows which have no name but have corrdinates. we will compute their name and postcode with the help of \n",
    "## coordinates\n",
    "\n",
    "\n",
    "def check(i):\n",
    "    \n",
    "    lon = corr.loc[corr['index']==i]['longitude'].mean()\n",
    "    lat = corr.loc[corr['index']==i]['latitude'].mean()\n",
    "\n",
    "    bw = 0.005\n",
    "    \n",
    "    length = len(pc_vic.loc[(pc_vic.latitude > lat-bw)& (pc_vic.latitude < lat+bw) & (pc_vic.longitude < lon+bw) & (pc_vic.longitude > lon-bw ) ]['postal code'])\n",
    "    \n",
    "    while length != 1:\n",
    "        \n",
    "        if length >= 2:\n",
    "            idx = pc_vic.loc[(pc_vic.latitude > lat-bw)& (pc_vic.latitude < lat+bw) & (pc_vic.longitude < lon+bw) & (pc_vic.longitude > lon-bw ) ]['postal code'].idxmax()\n",
    "            shape_2k8_20.loc[shape_2k8_20['index'] == i, 'postcode'] = int(pc_vic.iloc[idx,list(pc_vic.columns).index('postal code')])\n",
    "            shape_2k8_20.loc[shape_2k8_20['index'] == i, 'Place'] = pc_vic.iloc[idx,list(pc_vic.columns).index('place name')]\n",
    "            return\n",
    "\n",
    "\n",
    "        bw +=0.005\n",
    "        length = len(pc_vic.loc[(pc_vic.latitude > lat-bw)& (pc_vic.latitude < lat+bw) & (pc_vic.longitude < lon+bw) & (pc_vic.longitude > lon-bw ) ]['postal code'])\n",
    "     \n",
    "    ix = pc_vic.loc[(pc_vic.latitude > lat-bw)& (pc_vic.latitude < lat+bw) & (pc_vic.longitude < lon+bw) & (pc_vic.longitude > lon-bw ) ]['postal code'].index[0]\n",
    "    \n",
    "    shape_2k8_20.loc[shape_2k8_20['index'] == i, 'postcode'] = int(pc_vic.iloc[ix,list(pc_vic.columns).index('postal code')])\n",
    "    shape_2k8_20.loc[shape_2k8_20['index'] == i, 'Place'] = pc_vic.iloc[ix,list(pc_vic.columns).index('place name')]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2k8_20[shape_2k8_20['index'] == x[1]]  ## no name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr[corr['index'] == x[1]]  ### but have coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    check(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2k8_20.to_csv(\"final_shape_2k8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_2k8_20 = pd.read_csv(\"final_shape_2k8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing those data which don't have coordinates and 'NA' with no coordinates \n",
    "\n",
    "indx_list = []\n",
    "for i in x:\n",
    "    indx_list.append(shape_2k8_20[shape_2k8_20['index'] == i].index[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2k8_20.iloc[indx_list].to_csv('clean_shape_2k8.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2k8_20 = pd.read_csv('clean_shape_2k8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_2k8_20.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
